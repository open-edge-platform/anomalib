{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import datasets.mvtec as mvtec\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from cnn.efficientnet import EfficientNet as effnet\n",
    "from cnn.resnet import resnet18 as resnet18\n",
    "from cnn.resnet import wide_resnet50_2 as wide_resnet50_2\n",
    "from cnn.vgg import vgg19_bn as vgg19_bn\n",
    "from datasets.mvtec import MVTecDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.cfa import *\n",
    "from utils.cfa_new import CfaModel, get_feature_extractor\n",
    "from utils.metric import *\n",
    "from utils.visualizer import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\"CFA configuration\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"../../../datasets/MVTec/\")\n",
    "    parser.add_argument(\"--save_path\", type=str, default=\"./mvtec_result\")\n",
    "    parser.add_argument(\"--Rd\", type=bool, default=False)\n",
    "    parser.add_argument(\n",
    "        \"--cnn\",\n",
    "        type=str,\n",
    "        choices=[\"resnet18\", \"wide_resnet50_2\", \"efficientnet_b5\", \"vgg19_bn\"],\n",
    "        default=\"wide_resnet50_2\",\n",
    "    )\n",
    "    parser.add_argument(\"--resize\", type=int, choices=[224, 256], default=224)\n",
    "    parser.add_argument(\"--size\", type=int, choices=[224, 256], default=224)\n",
    "    parser.add_argument(\"--gamma_c\", type=int, default=1)\n",
    "    parser.add_argument(\"--gamma_d\", type=int, default=1)\n",
    "\n",
    "    parser.add_argument(\"--class_name\", type=str, default=\"zipper\")\n",
    "    parser.add_argument(\n",
    "        \"--backbone\",\n",
    "        type=str,\n",
    "        choices=[\"resnet18\", \"wide_resnet50_2\", \"efficientnet_b5\", \"vgg19_bn\"],\n",
    "        default=\"wide_resnet50_2\",\n",
    "    )\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "seed = 1024\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "args = parse_args()\n",
    "class_names = mvtec.CLASS_NAMES if args.class_name == \"all\" else [args.class_name]\n",
    "class_name = args.class_name\n",
    "\n",
    "train_dataset = MVTecDataset(\n",
    "    dataset_path=args.data_path,\n",
    "    class_name=class_name,\n",
    "    resize=args.resize,\n",
    "    cropsize=args.size,\n",
    "    is_train=True,\n",
    "    wild_ver=args.Rd,\n",
    ")\n",
    "\n",
    "test_dataset = MVTecDataset(\n",
    "    dataset_path=args.data_path,\n",
    "    class_name=class_name,\n",
    "    resize=args.resize,\n",
    "    cropsize=args.size,\n",
    "    is_train=False,\n",
    "    wild_ver=args.Rd,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:08<00:00,  6.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "loss_fn = DSVDD(model, train_loader, args.cnn, args.gamma_c, args.gamma_d, device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, (x, _, _) = next(enumerate(train_loader))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1490.4032, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "features = model(x.to(device))\n",
    "loss, _ = loss_fn(features)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 56, 56])\n",
      "torch.Size([4, 512, 28, 28])\n",
      "torch.Size([4, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils.cfa import Descriptor as OldDescriptor\n",
    "\n",
    "from anomalib.models.cfa.torch_model import Descriptor as NewDescriptor\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    torch.manual_seed(0)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# Create a feature map from Wide-ReNet50-2\n",
    "# input = [torch.rand(4, 256, 56, 56), torch.rand(4, 512, 28, 28), torch.rand(4, 1024, 14, 14)]\n",
    "input = [torch.rand(4, 256, 56, 56).cuda(), torch.rand(4, 512, 28, 28).cuda(), torch.rand(4, 1024, 14, 14).cuda()]\n",
    "use_cuda = True if input[0].device.type == \"cuda\" else False\n",
    "\n",
    "d1 = OldDescriptor(gamma_d=1, cnn=\"wide_resnet50_2\").to(input[0].device)\n",
    "d2 = NewDescriptor(gamma_d=1, backbone=\"wide_resnet50_2\").to(input[0].device)\n",
    "\n",
    "d1.apply(initialize_weights)\n",
    "d2.apply(initialize_weights)\n",
    "\n",
    "o1 = d1(input)\n",
    "o2 = d2(input)\n",
    "\n",
    "torch.allclose(o1, o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oriented_features = torch.rand((1, 1792, 56, 56))\n",
    "m1 = torch.mean(oriented_features, dim=0, keepdim=True)\n",
    "m2 = oriented_features.mean(dim=0, keepdim=True)\n",
    "\n",
    "torch.allclose(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((4, 3, 224, 224)).cuda()\n",
    "i = 0\n",
    "memory_bank = torch.tensor(0, requires_grad=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = model(x)\n",
    "    oriented_features = d1(features)\n",
    "    memory_bank = ((memory_bank * i) + oriented_features.mean(dim=0, keepdim=True)) / (i + 1)\n",
    "\n",
    "memory_bank = memory_bank.transpose(-1, -2).detach()\n",
    "\n",
    "print(memory_bank.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_bank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(int, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = features[0].size(2)\n",
    "type(scale), scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.models.cfa.torch_model import CfaModel\n",
    "from anomalib.models.cfa.utils.cfa import DSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:07<00:00,  7.56it/s]\n"
     ]
    }
   ],
   "source": [
    "cfa_old = DSVDD(model, train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:07<00:00,  7.79it/s]\n"
     ]
    }
   ],
   "source": [
    "cfa_new = CfaModel(model, train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(611152.9375, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.rand((4, 1792, 56, 56)).cuda()\n",
    "features = rearrange(features, \"b c h w -> b (h w) c\")\n",
    "loss = cfa_old._soft_boundary(features)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:43: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:56: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:43: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:56: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "/tmp/ipykernel_2697556/2651216444.py:43: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(torch.allclose(old_feature, new_feature, atol=1e-1), \"Old and new features should match.\")\n",
      "100%|██████████| 60/60 [00:07<00:00,  7.77it/s]\n",
      "100%|██████████| 60/60 [00:07<00:00,  7.76it/s]\n",
      "/tmp/ipykernel_2697556/2651216444.py:56: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert((old_loss - new_loss).abs()/1000 < 1e-1, \"Old and new losses should match.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.cfa import Descriptor as OldDescriptor\n",
    "\n",
    "from anomalib.models.cfa.cnn.resnet import wide_resnet50_2\n",
    "from anomalib.models.cfa.datasets.mvtec import MVTecDataset\n",
    "from anomalib.models.cfa.torch_model import CfaModel\n",
    "from anomalib.models.cfa.torch_model import CoordConv2d as NewCoordConv2d\n",
    "from anomalib.models.cfa.torch_model import Descriptor as NewDescriptor\n",
    "from anomalib.models.cfa.torch_model import get_feature_extractor\n",
    "from anomalib.models.cfa.utils.cfa import DSVDD\n",
    "from anomalib.models.cfa.utils.coordconv import CoordConv2d as OldCoordConv2d\n",
    "\n",
    "\n",
    "def initialize_weights(m) -> None:\n",
    "    torch.manual_seed(0)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity=\"relu\")\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "        device = torch.device(\"cuda\")\n",
    "        train_dataset = MVTecDataset(\"/home/sakcay/projects/anomalib/datasets/MVTec/\", \"zipper\")\n",
    "        train_loader = DataLoader(train_dataset, 4)\n",
    "\n",
    "\n",
    "# Compare the feature extractor\n",
    "_, (input, _, _) = next(enumerate(train_loader))\n",
    "input = input.cuda()\n",
    "\n",
    "old_feature_extractor = wide_resnet50_2(pretrained=True, progress=True).to(device)\n",
    "old_feature_extractor.eval()\n",
    "\n",
    "new_feature_extractor = get_feature_extractor(\"wide_resnet50_2\", device=torch.device(\"cuda\"))\n",
    "\n",
    "old_features = old_feature_extractor(input)\n",
    "new_features = new_feature_extractor(input)\n",
    "new_features = [val for val in new_features.values()]\n",
    "\n",
    "for old_feature, new_feature in zip(old_features, new_features):\n",
    "    assert torch.allclose(old_feature, new_feature, atol=1e-1), \"Old and new features should match.\"\n",
    "\n",
    "\n",
    "# Compute the memory bank.\n",
    "cfa_old = DSVDD(old_feature_extractor, train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)\n",
    "cfa_new = CfaModel(new_feature_extractor, train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)\n",
    "assert torch.allclose(cfa_old.C, cfa_new.memory_bank, atol=1e-1)\n",
    "assert cfa_new.memory_bank.requires_grad is False\n",
    "\n",
    "\n",
    "# Compute Forward-Pass.\n",
    "old_loss, _ = cfa_old(old_features)\n",
    "new_loss, _ = cfa_new(new_features)\n",
    "assert (old_loss - new_loss).abs() / 1000 < 1e-1, \"Old and new losses should match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1782.5446, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " tensor([[[[0.2759, 0.2337, 0.3223,  ..., 0.3570, 0.2941, 0.3232],\n",
       "           [0.2293, 0.3200, 0.3982,  ..., 0.4049, 0.3766, 0.2758],\n",
       "           [0.2537, 0.2877, 0.4034,  ..., 0.3845, 0.3050, 0.2768],\n",
       "           ...,\n",
       "           [0.3576, 0.4133, 0.4989,  ..., 0.3087, 0.2425, 0.2177],\n",
       "           [0.3463, 0.4520, 0.4932,  ..., 0.3214, 0.3161, 0.2245],\n",
       "           [0.3794, 0.3341, 0.3979,  ..., 0.2614, 0.2258, 0.2417]]],\n",
       " \n",
       " \n",
       "         [[[0.2157, 0.1812, 0.2434,  ..., 0.4345, 0.4311, 0.4588],\n",
       "           [0.1773, 0.2465, 0.2855,  ..., 0.5210, 0.5528, 0.4045],\n",
       "           [0.1785, 0.2006, 0.2577,  ..., 0.5137, 0.4807, 0.4416],\n",
       "           ...,\n",
       "           [0.1664, 0.2012, 0.2795,  ..., 0.5641, 0.5193, 0.4713],\n",
       "           [0.1745, 0.2443, 0.2802,  ..., 0.5432, 0.6477, 0.4538],\n",
       "           [0.1965, 0.1770, 0.2304,  ..., 0.4324, 0.4567, 0.4814]]],\n",
       " \n",
       " \n",
       "         [[[0.1802, 0.1520, 0.1995,  ..., 0.3348, 0.2626, 0.2925],\n",
       "           [0.1486, 0.2072, 0.2408,  ..., 0.3791, 0.3362, 0.2493],\n",
       "           [0.1580, 0.1776, 0.2399,  ..., 0.3479, 0.2748, 0.2452],\n",
       "           ...,\n",
       "           [0.3348, 0.3875, 0.4425,  ..., 0.3628, 0.2673, 0.2394],\n",
       "           [0.3187, 0.4296, 0.4412,  ..., 0.4312, 0.3714, 0.2710],\n",
       "           [0.3551, 0.3211, 0.3721,  ..., 0.3530, 0.2661, 0.3009]]],\n",
       " \n",
       " \n",
       "         [[[0.1751, 0.1474, 0.1888,  ..., 0.3812, 0.3258, 0.3502],\n",
       "           [0.1421, 0.1999, 0.2230,  ..., 0.4173, 0.4000, 0.2972],\n",
       "           [0.1479, 0.1682, 0.2158,  ..., 0.3786, 0.3153, 0.2881],\n",
       "           ...,\n",
       "           [0.2219, 0.2522, 0.3442,  ..., 0.4221, 0.3187, 0.2963],\n",
       "           [0.2380, 0.3168, 0.3650,  ..., 0.4775, 0.4185, 0.3108],\n",
       "           [0.2614, 0.2249, 0.2940,  ..., 0.3798, 0.2936, 0.3355]]]],\n",
       "        device='cuda:0', grad_fn=<ReshapeAliasBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anomalib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f26beec5b578f06009232863ae217b956681fd13da2e828fa5a0ecf8cf2ccd29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
