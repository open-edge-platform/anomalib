{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import datasets.mvtec as mvtec\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from cnn.efficientnet import EfficientNet as effnet\n",
    "from cnn.resnet import resnet18 as resnet18\n",
    "from cnn.resnet import wide_resnet50_2 as wide_resnet50_2\n",
    "from cnn.vgg import vgg19_bn as vgg19_bn\n",
    "from datasets.mvtec import MVTecDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.cfa import *\n",
    "from utils.cfa_new import get_feature_extractor, CfaModel\n",
    "from utils.metric import *\n",
    "from utils.visualizer import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\"CFA configuration\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"../../../datasets/MVTec/\")\n",
    "    parser.add_argument(\"--save_path\", type=str, default=\"./mvtec_result\")\n",
    "    parser.add_argument(\"--Rd\", type=bool, default=False)\n",
    "    parser.add_argument(\"--cnn\", type=str, choices=[\"resnet18\", \"wide_resnet50_2\", \"efficientnet_b5\", \"vgg19_bn\"], default=\"wide_resnet50_2\")\n",
    "    parser.add_argument(\"--resize\", type=int, choices=[224, 256], default=224)\n",
    "    parser.add_argument(\"--size\", type=int, choices=[224, 256], default=224)\n",
    "    parser.add_argument(\"--gamma_c\", type=int, default=1)\n",
    "    parser.add_argument(\"--gamma_d\", type=int, default=1)\n",
    "\n",
    "    parser.add_argument(\"--class_name\", type=str, default=\"zipper\")\n",
    "    parser.add_argument(\n",
    "            \"--backbone\",\n",
    "            type=str,\n",
    "            choices=[\"resnet18\", \"wide_resnet50_2\", \"efficientnet_b5\", \"vgg19_bn\"],\n",
    "            default=\"wide_resnet50_2\",\n",
    "        )\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "seed = 1024\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "args = parse_args()\n",
    "class_names = mvtec.CLASS_NAMES if args.class_name == \"all\" else [args.class_name]\n",
    "class_name = args.class_name\n",
    "\n",
    "train_dataset = MVTecDataset(\n",
    "    dataset_path=args.data_path,\n",
    "    class_name=class_name,\n",
    "    resize=args.resize,\n",
    "    cropsize=args.size,\n",
    "    is_train=True,\n",
    "    wild_ver=args.Rd,\n",
    ")\n",
    "\n",
    "test_dataset = MVTecDataset(\n",
    "    dataset_path=args.data_path,\n",
    "    class_name=class_name,\n",
    "    resize=args.resize,\n",
    "    cropsize=args.size,\n",
    "    is_train=False,\n",
    "    wild_ver=args.Rd,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:08<00:00,  7.39it/s]\n",
      "100%|██████████| 60/60 [00:08<00:00,  7.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.cfa import Descriptor as OldDescriptor\n",
    "\n",
    "from anomalib.models.cfa.cnn.resnet import wide_resnet50_2\n",
    "from anomalib.models.cfa.datasets.mvtec import MVTecDataset\n",
    "from anomalib.models.cfa.torch_model import CfaModel\n",
    "from anomalib.models.cfa.torch_model import CoordConv2d as NewCoordConv2d\n",
    "from anomalib.models.cfa.torch_model import Descriptor as NewDescriptor\n",
    "from anomalib.models.cfa.torch_model import get_feature_extractor\n",
    "from anomalib.models.cfa.utils.cfa import DSVDD\n",
    "from anomalib.models.cfa.utils.coordconv import CoordConv2d as OldCoordConv2d\n",
    "from anomalib.models.components import GaussianBlur2d\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "train_dataset = MVTecDataset(\"/home/sakcay/projects/anomalib/datasets/MVTec/\", \"zipper\")\n",
    "train_loader = DataLoader(train_dataset, 4)\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Compare the feature extractor\n",
    "_, (input, _, _) = next(enumerate(train_loader))\n",
    "input = input.cuda()\n",
    "\n",
    "old_feature_extractor = wide_resnet50_2(pretrained=True, progress=True).to(device)\n",
    "old_feature_extractor.eval()\n",
    "\n",
    "new_feature_extractor = get_feature_extractor(\"wide_resnet50_2\", device=torch.device(\"cuda\"))\n",
    "\n",
    "old_features = old_feature_extractor(input)\n",
    "new_features = new_feature_extractor(input)\n",
    "new_features = [val for val in new_features.values()]\n",
    "\n",
    "for old_feature, new_feature in zip(old_features, new_features):\n",
    "    assert torch.allclose(old_feature, new_feature, atol=1e-1), \"Old and new features should match.\"\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Compute the memory bank.\n",
    "cfa_old = DSVDD(old_feature_extractor, train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)\n",
    "cfa_new = CfaModel(train_loader, \"wide_resnet50_2\", 1, 1, device).to(device)\n",
    "assert torch.allclose(cfa_old.C, cfa_new.memory_bank, atol=1e-1)\n",
    "assert cfa_new.memory_bank.requires_grad is False\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Compute Forward-Pass.\n",
    "old_loss, old_score = cfa_old(old_features)\n",
    "\n",
    "cfa_new.train()\n",
    "new_loss = cfa_new(input)\n",
    "\n",
    "assert (old_loss - new_loss).abs() / 1000 < 1e-1, \"Old and new losses should match.\"\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Compute Anomaly Map.\n",
    "heatmaps = None\n",
    "old_loss, old_score = cfa_old(old_features)\n",
    "heatmap = old_score.cpu().detach()\n",
    "heatmap = torch.mean(heatmap, dim=1)\n",
    "heatmaps = torch.cat((heatmaps, heatmap), dim=0) if heatmaps != None else heatmap\n",
    "\n",
    "heatmaps = upsample(heatmaps, size=input.size(2), mode=\"bilinear\")\n",
    "heatmaps = gaussian_smooth(heatmaps, sigma=4)\n",
    "heatmaps = torch.tensor(heatmaps).cuda().unsqueeze(1)\n",
    "\n",
    "cfa_new.train()\n",
    "new_loss = cfa_new(input)\n",
    "\n",
    "cfa_new.eval()\n",
    "new_heatmaps = cfa_new(input)\n",
    "assert torch.allclose(heatmaps, new_heatmaps, atol=1e-1), \"Old and new heatmaps should match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = list()\n",
    "gt_mask_list = list()\n",
    "gt_list = list()\n",
    "heatmaps1 = None\n",
    "\n",
    "cfa_old.eval()\n",
    "for x, y, mask in test_loader:\n",
    "    test_imgs.extend(x.cpu().detach().numpy())\n",
    "    # gt_list.extend(y.cpu().detach().numpy())\n",
    "    # gt_mask_list.extend(mask.cpu().detach().numpy())\n",
    "\n",
    "    p = old_feature_extractor(x.to(device))\n",
    "    _, score = cfa_old(p)\n",
    "    heatmap1 = score.cpu().detach()\n",
    "    heatmap1 = torch.mean(heatmap1, dim=1)\n",
    "    heatmaps1 = torch.cat((heatmaps1, heatmap1), dim=0) if heatmaps1 != None else heatmap1\n",
    "\n",
    "heatmaps1 = upsample(heatmaps1, size=x.size(2), mode=\"bilinear\")\n",
    "heatmaps1 = gaussian_smooth(heatmaps1, sigma=4)\n",
    "\n",
    "gt_mask = np.asarray(gt_mask_list)\n",
    "heatmaps1 = rescale(heatmaps1)\n",
    "\n",
    "test_imgs = list()\n",
    "gt_mask_list = list()\n",
    "gt_list = list()\n",
    "heatmaps = None\n",
    "\n",
    "cfa_old.eval()\n",
    "i, (x, y, mask) = next(enumerate(test_loader))\n",
    "test_imgs.extend(x.cpu().detach().numpy())\n",
    "# gt_list.extend(y.cpu().detach().numpy())\n",
    "# gt_mask_list.extend(mask.cpu().detach().numpy())\n",
    "\n",
    "p = old_feature_extractor(x.to(device))\n",
    "_, score = cfa_old(p)\n",
    "heatmap = score.cpu().detach()\n",
    "heatmap = torch.mean(heatmap, dim=1)\n",
    "heatmaps = torch.cat((heatmaps, heatmap), dim=0) if heatmaps != None else heatmap\n",
    "\n",
    "heatmaps = upsample(heatmaps, size=x.size(2), mode=\"bilinear\")\n",
    "heatmaps = gaussian_smooth(heatmaps, sigma=4)\n",
    "\n",
    "gt_mask = np.asarray(gt_mask_list)\n",
    "# heatmaps = rescale(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = score.cpu().detach()\n",
    "heatmap = torch.mean(heatmap, dim=1)\n",
    "heatmaps = torch.cat((heatmaps, heatmap), dim=0) if heatmaps != None else heatmap\n",
    "\n",
    "heatmaps = upsample(heatmaps, size=x.size(2), mode=\"bilinear\")\n",
    "heatmaps = gaussian_smooth(heatmaps, sigma=4)\n",
    "\n",
    "gt_mask = np.asarray(gt_mask_list)\n",
    "# heatmaps = rescale(heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 224, 224])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfa_new.eval()\n",
    "new_heatmap = cfa_new(x.cuda())\n",
    "new_heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch.tensor(heatmaps1).unsqueeze(1).cuda(), new_heatmap, atol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anomalib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f26beec5b578f06009232863ae217b956681fd13da2e828fa5a0ecf8cf2ccd29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
