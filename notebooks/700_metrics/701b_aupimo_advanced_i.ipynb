{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUPIMO\n",
    "\n",
    "Advance use cases of the metric AUPIMO (pronounced \"a-u-pee-mo\").\n",
    "\n",
    "> For basic usage, please check the notebook [701a_aupimo.ipynb](./701a_aupimo.ipynb).\n",
    "\n",
    "Includes:\n",
    "- selection of test representative samples for qualitative analysis\n",
    "- visualization of the AUPIMO metric with heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is AUPIMO?\n",
    "\n",
    "The `Area Under the Per-Image Overlap [curve]` (AUPIMO) is a metric of recall (higher is better) designed for visual anomaly detection.\n",
    "\n",
    "Inspired by the [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and [PRO](https://link.springer.com/article/10.1007/s11263-020-01400-4) curves, \n",
    "\n",
    "> AUPIMO is the area under a curve of True Positive Rate (TPR or _recall_) as a function of False Positive Rate (FPR) restricted to a fixed range. \n",
    "\n",
    "But:\n",
    "- the TPR (Y-axis) is *per-image* (1 image = 1 curve/score);\n",
    "- the FPR (X-axis) considers the (average of) **normal** images only; \n",
    "- the FPR (X-axis) is in log scale and its range is [1e-5, 1e-4]\\* (harder detection task!).\n",
    "\n",
    "\\* The score (the area under the curve) is normalized to be in [0, 1].\n",
    "\n",
    "AUPIMO can be interpreted as\n",
    "\n",
    "> average segmentation recall in an image given that the model (nearly) does not yield false positives in normal images.\n",
    "\n",
    "References in the last cell.\n",
    "\n",
    "![AUROC vs. AUPRO vs. AUPIMO](./roc_pro_pimo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `anomalib` using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(jpcbertoldo): replace by `pip install anomalib` when AUPIMO is released  # noqa: TD003\n",
    "%pip install ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the directory to have access to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# NOTE: Provide the path to the dataset root directory.\n",
    "#   If the datasets is not downloaded, it will be downloaded\n",
    "#   to this directory.\n",
    "dataset_root = Path.cwd().parent.parent / \"datasets\" / \"MVTec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from scipy import stats\n",
    "\n",
    "from anomalib import TaskType\n",
    "from anomalib.data import MVTec\n",
    "from anomalib.data.utils import read_image\n",
    "from anomalib.engine import Engine\n",
    "from anomalib.metrics import AUPIMO, Evaluator\n",
    "from anomalib.models import Padim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "This part was covered in the notebook [701a_aupimo.ipynb](./701a_aupimo.ipynb), so we'll not discuss it here.\n",
    "\n",
    "It will train a model and evaluate it using AUPIMO.\n",
    "We will use dataset Leather from MVTec AD with `PaDiM` (performance is not the best, but it is fast to train).\n",
    "\n",
    "> See the notebooks below for more details on:\n",
    "> - datamodules: [100_datamodules](https://github.com/openvinotoolkit/anomalib/tree/main/notebooks/100_datamodules);\n",
    "> - models: [200_models](https://github.com/openvinotoolkit/anomalib/tree/main/notebooks/200_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "task = TaskType.SEGMENTATION\n",
    "datamodule = MVTec(\n",
    "    root=dataset_root,\n",
    "    category=\"leather\",\n",
    "    image_size=256,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    num_workers=8,\n",
    "    task=task,\n",
    ")\n",
    "evaluator = Evaluator(test_metrics=AUPIMO())\n",
    "model = Padim(\n",
    "    # only use one layer to speed it up\n",
    "    layers=[\"layer1\"],\n",
    "    n_features=64,\n",
    "    backbone=\"resnet18\",\n",
    "    pre_trained=True,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "engine = Engine(\n",
    "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
    "    devices=1,\n",
    "    logger=False,\n",
    ")\n",
    "engine.fit(datamodule=datamodule, model=model)\n",
    "# infer\n",
    "predictions = engine.predict(dataloaders=datamodule.test_dataloader(), model=model, return_predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AUPIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aupimo = AUPIMO(\n",
    "    # with `False` all the values are returned in a dataclass\n",
    "    return_average=False,\n",
    ")\n",
    "\n",
    "anomaly_maps = []\n",
    "masks = []\n",
    "labels = []\n",
    "image_paths = []\n",
    "for batch in predictions:\n",
    "    anomaly_maps.append(batch.anomaly_map.squeeze(dim=1))\n",
    "    masks.append(batch.gt_mask)\n",
    "    labels.append(batch.gt_label)\n",
    "    image_paths.append(batch.image_path)\n",
    "    aupimo.update(batch)\n",
    "\n",
    "# list[list[str]] -> list[str]\n",
    "image_paths = [item for sublist in image_paths for item in sublist]\n",
    "anomaly_maps = torch.cat(anomaly_maps, dim=0)\n",
    "masks = torch.cat(masks, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "# `pimo_result` has the PIMO curves of each image\n",
    "# `aupimo_result` has the AUPIMO values\n",
    "#     i.e. their Area Under the Curve (AUC)\n",
    "pimo_result, aupimo_result = aupimo.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics and score distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the normal images have `nan` values because\n",
    "# recall is not defined for them so we ignore them\n",
    "print(f\"MEAN\\n{aupimo_result.aupimos[labels == 1].mean().item()=}\")\n",
    "print(f\"OTHER STATISTICS\\n{stats.describe(aupimo_result.aupimos[labels == 1])}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(aupimo_result.aupimos[labels == 1].numpy(), bins=np.linspace(0, 1, 11), edgecolor=\"black\")\n",
    "ax.set_ylabel(\"Count (number of images)\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel(\"AUPIMO [%]\")\n",
    "ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.grid()\n",
    "ax.set_title(\"AUPIMO distribution\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until here we just reproduded the notebook with the basic usage of AUPIMO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Representative Samples for Qualitative Analysis\n",
    "\n",
    "Instead of cherry picking or inspecting the 92 samples from above, we'll try to choose them smartly.\n",
    "\n",
    "Our goal here is to select a handful of samples in a meaningful way.\n",
    "\n",
    "> Notice that a random selection from the distribution above would probably miss the worst cases.\n",
    "\n",
    "We will summarize this distribution with a boxplot, then select the samples corresponding to the statistics in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "boxplot_data = ax.boxplot(\n",
    "    aupimo_result.aupimos[labels == 1].numpy(),\n",
    "    vert=False,\n",
    "    widths=0.4,\n",
    ")\n",
    "_ = ax.set_yticks([])\n",
    "ax.set_xlim(0 - (eps := 2e-2), 1 + eps)\n",
    "ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.set_xlabel(\"AUPIMO [%]\")\n",
    "ax.set_title(\"AUPIMO Scores Boxplot\")\n",
    "num_images = (labels == 1).sum().item()\n",
    "ax.annotate(\n",
    "    text=f\"Number of images: {num_images}\",\n",
    "    xy=(0.03, 0.95),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(0, 0),\n",
    "    textcoords=\"offset points\",\n",
    "    annotation_clip=False,\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the values in the boxplot (e.g., whiskers, quartiles, etc.), we're going to use `matplotlib`'s internal function `mpl.cbook.boxplot_stats()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_data = mpl.cbook.boxplot_stats(aupimo_result.aupimos[labels == 1].numpy())[0]\n",
    "print(boxplot_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select 5 of those and find images in the dataset that match them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_selection = []\n",
    "\n",
    "for key in [\"whislo\", \"q1\", \"med\", \"q3\", \"whishi\"]:\n",
    "    value = boxplot_data[key]\n",
    "    # find the image that is closest to the value of the statistic\n",
    "    #     `[labels == 1]` is not used here so that the image's\n",
    "    #         indexes are the same as the ones in the dataset\n",
    "    #     we use `sort()` -- instead of `argmin()` -- so that\n",
    "    #         the `nan`s are not considered (they are at the end)\n",
    "    closest_image_index = (aupimo_result.aupimos - value).abs().argsort()[0]\n",
    "    image_selection.append({\"statistic\": key, \"value\": value, \"image_index\": closest_image_index.item()})\n",
    "\n",
    "image_selection = pd.DataFrame(image_selection)\n",
    "print(image_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that they are sorted from the worst to the best AUPIMO score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Representative Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what the heatmaps of these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be used to normalize the anomaly maps to fit a colormap\n",
    "global_vmin, global_vmax = torch.quantile(anomaly_maps, torch.tensor([0.02, 0.98]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(16, 7), layout=\"constrained\")\n",
    "\n",
    "for ax_column, (_, row) in zip(axes.T, image_selection.iterrows(), strict=False):\n",
    "    ax_above, ax_below = ax_column\n",
    "    image = cv2.resize(read_image(image_paths[row.image_index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[row.image_index].numpy()\n",
    "    mask = masks[row.image_index].squeeze().numpy()\n",
    "    ax_above.imshow(image)\n",
    "    ax_above.contour(mask, levels=[0.5], colors=\"magenta\", linewidths=1)\n",
    "    ax_below.imshow(image)\n",
    "    ax_below.imshow(anomaly_map, cmap=\"jet\", vmin=global_vmin, vmax=global_vmax, alpha=0.30)\n",
    "    ax_below.contour(mask, levels=[0.5], colors=\"magenta\", linewidths=1)\n",
    "    ax_above.set_title(f\"{row.statistic}: {row.value:.0%} AUPIMO  image {row.image_index}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Image + GT Mask\")\n",
    "axes[1, 0].set_ylabel(\"Image + GT Mask + Anomaly Map\")\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Magenta: contours of the ground truth (GT) mask. \"\n",
    "    \"Anomaly maps colored in JET colormap with global (across all images) min-max normalization.\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=\"small\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Anomalous samples from AUPIMO boxplot's statistics\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmaps give the impression that all samples are properly detected, right?\n",
    "\n",
    "Notice that the lowest AUPIMO (left) is 0, but the heatmap is (contradictorily) showing a good detection.\n",
    "\n",
    "Why is that?\n",
    "\n",
    "These heatmaps are colored with a gradient from the minimum to the maximum value in all the heatmaps from the test set.\n",
    "\n",
    "This is not taking into account the contraints (FPR restriction) in AUPIMO.\n",
    "\n",
    "Let's compare with the heatmaps from some normal images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(16, 7), layout=\"constrained\")\n",
    "\n",
    "# random selection of normal images\n",
    "rng = np.random.default_rng(42)\n",
    "normal_images_selection = rng.choice(np.where(labels == 0)[0], size=5, replace=False)\n",
    "\n",
    "for ax_column, index in zip(axes.T, normal_images_selection, strict=False):\n",
    "    ax_above, ax_below = ax_column\n",
    "    image = cv2.resize(read_image(image_paths[index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[index].numpy()\n",
    "    ax_above.imshow(image)\n",
    "    ax_below.imshow(image)\n",
    "    ax_below.imshow(anomaly_map, cmap=\"jet\", vmin=global_vmin, vmax=global_vmax, alpha=0.30)\n",
    "    ax_above.set_title(f\"image {index}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Image\")\n",
    "axes[1, 0].set_ylabel(\"Image + Anomaly Map\")\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Anomaly maps colored in JET colormap with global (across all images) min-max normalization.\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=\"small\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Normal samples (test set)\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the normal images also have high anomaly scores (\"hot\" colors) although there is no anomaly.\n",
    "\n",
    "As a matter of fact, the heatmaps can barely differentiate between some normal and anomalous images.\n",
    "\n",
    "See the two heatmaps below for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7, 4), layout=\"constrained\")\n",
    "\n",
    "for ax, index in zip(axes.flatten(), [87, 65], strict=False):\n",
    "    image = cv2.resize(read_image(image_paths[index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[index].numpy()\n",
    "    mask = masks[index].squeeze().numpy()\n",
    "    ax.imshow(image)\n",
    "    ax.contour(mask, levels=[0.5], colors=\"magenta\", linewidths=1)\n",
    "    ax.imshow(anomaly_map, cmap=\"jet\", vmin=global_vmin, vmax=global_vmax, alpha=0.30)\n",
    "    ax.set_title(f\"image {index}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[0].set_title(f\"{axes[0].get_title()} (normal)\")\n",
    "axes[1].set_title(f\"{axes[1].get_title()} (anomalous)\")\n",
    "\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Magenta: contours of the ground truth (GT) mask.\\n\"\n",
    "    \"Anomaly maps colored in JET colormap with global (across all images) min-max normalization.\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=\"small\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Normal vs. Anomalous Samples\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One would expect image 65 (anomalous) to a 'hotter' heatmap than image 87 (normal), but it is the opposite.\n",
    "\n",
    "This shows that the model is not doing a great job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the AUPIMO on the Heatmaps\n",
    "\n",
    "We will create another visualization to link the heatmaps to AUPIMO.\n",
    "\n",
    "Recall that AUPIMO computes this integral (simplified):\n",
    "\n",
    "$$\n",
    "    \\int_{\\log(L)}^{\\log(U)} \n",
    "    \\operatorname{TPR}^{i}\\left( \\operatorname{FRP^{-1}}( z ) \\right)\n",
    "    \\, \n",
    "    \\mathrm{d}\\log(z)   \n",
    "$$\n",
    "\n",
    "The integration bounds -- $L$[ower] and $U$[pper] -- are FPR values.\n",
    "\n",
    "> More details about their meaning in the next notebook.\n",
    "\n",
    "We will leverage these two bounds to create a heatmap that shows them in a gradient like this:\n",
    "\n",
    "![Visualization of AUPIMO on the heatmaps](./pimo_viz.svg)\n",
    "\n",
    "If the anomaly score is\n",
    "1. too low (below the lowest threshold of AUPIMO) $\\rightarrow$ not shown; \n",
    "2. between the bounds $\\rightarrow$ shown in a JET gradient;\n",
    "3. too high (above the highest threshold of AUPIMO) $\\rightarrow$ shown in a single color.\n",
    "\n",
    "> Technical detail: lower/upper bound of FPR correspond to the upper/lower bound of threshold.\n",
    "\n",
    "> **Why low values are not shown?**\n",
    ">\n",
    "> Because the values below the lower (threshold) bound would  _never_  be seen as \"anomalous\" by the metric.\n",
    ">\n",
    "> Analogously, high values are shown in red because they are  _always_  seen as \"anomalous\" by the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fpr bounds are fixed in advance in the metric object\n",
    "print(f\"\"\"FPR bounds\n",
    "Lower bound: {aupimo.fpr_bounds[0]:.5f}\n",
    "Upper bound: {aupimo.fpr_bounds[1]:.5f}\"\"\")\n",
    "\n",
    "# their corresponding thresholds depend on the model's behavior\n",
    "# so they only show in the result object\n",
    "print(f\"\"\"Thresholds corresponding to the FPR bounds\n",
    "Lower threshold: {aupimo_result.thresh_lower_bound:.3g}\n",
    "Upper threshold: {aupimo_result.thresh_upper_bound:.3g}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we re-sample other normal images\n",
    "#    the FPR bounds are so strict that the heatmaps in the normal images\n",
    "#    become almost invisible with this colormap\n",
    "max_anom_score_per_image = anomaly_maps.max(dim=2).values.max(dim=1).values  # noqa: PD011\n",
    "normal_images_with_highest_max_score = sorted(\n",
    "    zip(max_anom_score_per_image[labels == 0], torch.where(labels == 0)[0], strict=False),\n",
    "    reverse=True,\n",
    "    key=lambda x: x[0],\n",
    ")\n",
    "normal_images_with_highest_max_score = [idx.item() for _, idx in normal_images_with_highest_max_score[:5]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 7), layout=\"constrained\")\n",
    "\n",
    "for ax, (_, row) in zip(axes[0], image_selection.iterrows(), strict=False):\n",
    "    image = cv2.resize(read_image(image_paths[row.image_index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[row.image_index].numpy()\n",
    "    mask = masks[row.image_index].squeeze().numpy()\n",
    "    ax.imshow(image)\n",
    "    #\n",
    "    # where the magic happens!\n",
    "    #\n",
    "    ax.imshow(\n",
    "        # anything below the lower threshold is set to `nan` so it's not shown\n",
    "        #    because such values would never be detected as anomalies with AUPIMO's contraints\n",
    "        np.where(anomaly_map < aupimo_result.thresh_lower_bound, np.nan, anomaly_map),\n",
    "        cmap=\"jet\",\n",
    "        alpha=0.50,\n",
    "        # notice that vmin/vmax changed here to use the thresholds from the result object\n",
    "        vmin=aupimo_result.thresh_lower_bound,\n",
    "        vmax=aupimo_result.thresh_upper_bound,\n",
    "    )\n",
    "    ax.contour(anomaly_map, levels=[aupimo_result.thresh_lower_bound], colors=[\"blue\"], linewidths=1)\n",
    "    ax.contour(mask, levels=[0.5], colors=\"magenta\", linewidths=1)\n",
    "    ax.set_title(f\"{row.statistic}: {row.value:.0%}AUPIMO  image {row.image_index}\")\n",
    "\n",
    "for ax, index in zip(axes[1], normal_images_with_highest_max_score, strict=False):\n",
    "    image = cv2.resize(read_image(image_paths[index]), (256, 256))\n",
    "    anomaly_map = anomaly_maps[index].numpy()\n",
    "    mask = masks[index].squeeze().numpy()\n",
    "    ax.imshow(image)\n",
    "    ax.imshow(\n",
    "        np.where(anomaly_map < aupimo_result.thresh_lower_bound, np.nan, anomaly_map),\n",
    "        cmap=\"jet\",\n",
    "        alpha=0.30,\n",
    "        vmin=aupimo_result.thresh_lower_bound,\n",
    "        vmax=aupimo_result.thresh_upper_bound,\n",
    "    )\n",
    "    ax.contour(anomaly_map, levels=[aupimo_result.thresh_lower_bound], colors=[\"blue\"], linewidths=1)\n",
    "    ax.set_title(f\"image {index}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Anomalous\")\n",
    "axes[1, 0].set_ylabel(\"Normal\")\n",
    "fig.text(\n",
    "    0.03,\n",
    "    -0.01,\n",
    "    \"Magenta: contours of the ground truth (GT) mask. \"\n",
    "    \"Anomaly maps colored in JET colormap between the thresholds in AUPIMO's integral. \"\n",
    "    \"Lower values are transparent, higher values are red.\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    fontsize=\"small\",\n",
    "    color=\"dimgray\",\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Visualization linked to AUPIMO's bounds\")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the AUPIMO scores make sense with what you see in the heatmaps.\n",
    "\n",
    "The samples on the left and right are special cases: \n",
    "- left (0% AUPIMO): nothing is seen because the model completely misses the anomaly\\*;\n",
    "- right (100% AUPIMO): is practically red only because the detected the anomaly very well.  \n",
    "\n",
    "\\* Because the scores in image 65 are as low as those in normal images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cite Us\n",
    "\n",
    "AUPIMO was developed during Google Summer of Code 2023 (GSoC 2023) with the `anomalib` team from OpenVINO Toolkit.\n",
    "\n",
    "Our work was accepted to the British Machine Vision Conference 2024 (BMVC 2024).\n",
    "\n",
    "```bibtex\n",
    "@misc{bertoldo2024aupimo,\n",
    "      title={{AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed and Low Tolerance}}, \n",
    "      author={Joao P. C. Bertoldo and Dick Ameln and Ashwin Vaidya and Samet Akçay},\n",
    "      year={2024},\n",
    "      eprint={2401.01984},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV},\n",
    "      url={https://arxiv.org/abs/2401.01984}, \n",
    "}\n",
    "```\n",
    "\n",
    "Paper on arXiv: [arxiv.org/abs/2401.01984](https://arxiv.org/abs/2401.01984) (accepted to BMVC 2024)\n",
    "\n",
    "Medium post: [medium.com/p/c653ac30e802](https://medium.com/p/c653ac30e802)\n",
    "\n",
    "Official repository: [github.com/jpcbertoldo/aupimo](https://github.com/jpcbertoldo/aupimo) (numpy-only API and numba-accelerated versions available)\n",
    "\n",
    "GSoC 2023 page: [summerofcode.withgoogle.com/archive/2023/projects/SPMopugd](https://summerofcode.withgoogle.com/archive/2023/projects/SPMopugd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "Here we provide some utility functions to reproduce the techniques shown in this notebook.\n",
    "\n",
    "They are `numpy` compatible and cover edge cases not discussed here (check the examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representative samples from the boxplot's statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def _validate_tensor_or_ndarray(x: Tensor | ndarray) -> ndarray:\n",
    "    if not isinstance(x, Tensor | ndarray):\n",
    "        msg = f\"Expected argument to be a tensor or ndarray, but got {type(x)}.\"\n",
    "        raise TypeError(msg)\n",
    "\n",
    "    if isinstance(x, Tensor):\n",
    "        x = x.cpu().numpy()\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _validate_values(values: ndarray) -> None:\n",
    "    if values.ndim != 1:\n",
    "        msg = f\"Expected argument `values` to be a 1D, but got {values.ndim}D.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "\n",
    "def _validate_labels(labels: ndarray) -> ndarray:\n",
    "    if labels.ndim != 1:\n",
    "        msg = f\"Expected argument `labels` to be a 1D, but got {labels.ndim}D.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # if torch.is_floating_point(labels):\n",
    "    if np.issubdtype(labels.dtype, np.floating):\n",
    "        msg = f\"Expected argument `labels` to be of int or binary types, but got float: {labels.dtype}.\"\n",
    "        raise TypeError(msg)\n",
    "\n",
    "    # check if it is binary and convert to int\n",
    "    if np.issubdtype(labels.dtype, np.bool_):\n",
    "        labels = labels.astype(int)\n",
    "\n",
    "    unique_values = np.unique(labels)\n",
    "    nor_0_nor_1 = (unique_values != 0) & (unique_values != 1)\n",
    "    if nor_0_nor_1.any():\n",
    "        msg = f\"Expected argument `labels` to have 0s and 1s as ground truth labels, but got values {unique_values}.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def boxplot_stats(\n",
    "    values: Tensor | ndarray,\n",
    "    labels: Tensor | ndarray,\n",
    "    only_label: int | None = 1,\n",
    "    flier_policy: str | None = None,\n",
    "    repeated_policy: str | None = \"avoid\",\n",
    ") -> list[dict[str, str | int | float | None]]:\n",
    "    \"\"\"Compute boxplot statistics of `values` and find the samples that are closest to them.\n",
    "\n",
    "    This function uses `matplotlib.cbook.boxplot_stats`, which is the same function used by `matplotlib.pyplot.boxplot`.\n",
    "\n",
    "    Args:\n",
    "        values (Tensor | ndarray): Values to compute boxplot statistics from.\n",
    "        labels (Tensor | ndarray): Labels of the samples (0=normal, 1=anomalous). Must have the same shape as `values`.\n",
    "        only_label (int | None): If 0 or 1, only use samples of that class. If None, use both. Defaults to 1.\n",
    "        flier_policy (str | None): What happens with the fliers ('outliers')?\n",
    "                                        - None: Do not include fliers.\n",
    "                                        - 'high': Include only high fliers.\n",
    "                                        - 'low': Include only low fliers.\n",
    "                                        - 'both': Include both high and low fliers.\n",
    "                                    Defaults to None.\n",
    "        repeated_policy (str | None): What happens if a sample has already selected [for another statistic]?\n",
    "                                        - None: Don't care, repeat the sample.\n",
    "                                        - 'avoid': Avoid selecting the same one, go to the next closest.\n",
    "                                        Defaults to 'avoid'.\n",
    "\n",
    "    Returns:\n",
    "        list[dict[str, str | int | float | None]]: List of boxplot statistics.\n",
    "            Keys:\n",
    "                - 'statistic' (str): Name of the statistic.\n",
    "                - 'value' (float): Value of the statistic (same units as `values`).\n",
    "                - 'nearest' (float): Value of the sample in `values` that is closest to the statistic.\n",
    "                            Some statistics (e.g. 'mean') are not guaranteed to be a value in `values`.\n",
    "                            This value is the actual one when they that is the case.\n",
    "                - 'index': Index in `values` that has the `nearest` value to the statistic.\n",
    "    \"\"\"\n",
    "    # operate on numpy arrays only for simplicity\n",
    "    values = _validate_tensor_or_ndarray(values)  # (N,)\n",
    "    labels = _validate_tensor_or_ndarray(labels)  # (N,)\n",
    "\n",
    "    # validate the arguments\n",
    "    _validate_values(values)\n",
    "    labels = _validate_labels(labels)\n",
    "    if values.shape != labels.shape:\n",
    "        msg = (\n",
    "            \"Expected arguments `values` and `labels` to have the same shape, \"\n",
    "            f\"but got {values.shape=} and {labels.shape=}.\"\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "    assert only_label in {None, 0, 1}, f\"Invalid argument `only_label`: {only_label}\"\n",
    "    assert flier_policy in {None, \"high\", \"low\", \"both\"}, f\"Invalid argument `flier_policy`: {flier_policy}\"\n",
    "    assert repeated_policy in {None, \"avoid\"}, f\"Invalid argument `repeated_policy`: {repeated_policy}\"\n",
    "\n",
    "    if only_label is not None and only_label not in labels:\n",
    "        msg = f\"Argument {only_label=} but `labels` does not contain this class.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # only consider samples of the given label\n",
    "    # `values` and `labels` now have shape (n,) instead of (N,), where n <= N\n",
    "    label_filter_mask = (labels == only_label) if only_label is not None else np.ones_like(labels, dtype=bool)\n",
    "    values = values[label_filter_mask]  # (n,)\n",
    "    labels = labels[label_filter_mask]  # (n,)\n",
    "    indexes = np.nonzero(label_filter_mask)[0]  # (n,) values are indices in  {0, 1, ..., N-1}\n",
    "\n",
    "    indexes_selected = set()  # values in {0, 1, ..., N-1}\n",
    "\n",
    "    def append(records_: dict, statistic_: str, value_: float) -> None:\n",
    "        indices_sorted_by_distance = np.abs(values - value_).argsort()  # (n,)\n",
    "        candidate = indices_sorted_by_distance[0]  # idx that refers to {0, 1, ..., n-1}\n",
    "\n",
    "        nearest = values[candidate]\n",
    "        index = indexes[candidate]  # index has value in {0, 1, ..., N-1}\n",
    "        label = labels[candidate]\n",
    "\n",
    "        if index in indexes_selected and repeated_policy == \"avoid\":\n",
    "            for candidate in indices_sorted_by_distance:\n",
    "                index_of_candidate = indexes[candidate]\n",
    "                if index_of_candidate in indexes_selected:\n",
    "                    continue\n",
    "                # if the code reaches here, it means that `index_of_candidate` is not repeated\n",
    "                # if this is never reached, the first choice will be kept\n",
    "                nearest = values[candidate]\n",
    "                label = labels[candidate]\n",
    "                index = index_of_candidate\n",
    "                break\n",
    "\n",
    "        indexes_selected.add(index)\n",
    "\n",
    "        records_.append(\n",
    "            {\n",
    "                \"statistic\": statistic_,\n",
    "                \"value\": float(value_),\n",
    "                \"nearest\": float(nearest),\n",
    "                \"index\": int(index),\n",
    "                \"label\": int(label),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    # function used in `matplotlib.boxplot`\n",
    "    boxplot_stats = mpl.cbook.boxplot_stats(values)[0]  # [0] is for the only boxplot\n",
    "\n",
    "    records = []\n",
    "    for stat, val in boxplot_stats.items():\n",
    "        if stat in {\"iqr\", \"cilo\", \"cihi\"}:\n",
    "            continue\n",
    "\n",
    "        if stat != \"fliers\":\n",
    "            append(records, stat, val)\n",
    "            continue\n",
    "\n",
    "        if flier_policy is None:\n",
    "            continue\n",
    "\n",
    "        for val_ in val:\n",
    "            stat_ = \"flierhi\" if val_ > boxplot_stats[\"med\"] else \"flierlo\"\n",
    "            if flier_policy == \"high\" and stat_ == \"flierlo\":\n",
    "                continue\n",
    "            if flier_policy == \"low\" and stat_ == \"flierhi\":\n",
    "                continue\n",
    "            # else means that they match or `fliers == \"both\"`\n",
    "            append(records, stat_, val_)\n",
    "\n",
    "    return sorted(records, key=lambda r: r[\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic usage\n",
    "boxplot_statistics = boxplot_stats(aupimo_result.aupimos, labels)\n",
    "boxplot_statistics = pd.DataFrame.from_records(boxplot_statistics)\n",
    "print(boxplot_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated values\n",
    "#   if the distribution is very skewed to one side,\n",
    "#   some statistics may have the same value\n",
    "#   e.g. the Q3 and the high whisker\n",
    "#\n",
    "#   let's simulate this situation\n",
    "\n",
    "# increase all values by 10% and clip to [0, 1]\n",
    "mock = torch.clip(aupimo_result.aupimos.clone() * 1.10, 0, 1)\n",
    "\n",
    "# 'avoid' is the default policy\n",
    "# notice how Q3 and the high whisker have the same value, but different indexes\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, repeated_policy=\"avoid\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this behavior can be changed to allow repeated values\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, repeated_policy=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fliers\n",
    "#    if the distribution is very skewed to one side,\n",
    "#    it is possible that some extreme values are considered\n",
    "#    are considered as outliers, showing as fliers in the boxplot\n",
    "#\n",
    "#    there are two types of fliers: high and low\n",
    "#    they are defined as:\n",
    "#        - high: values > high whisker = Q3 + 1.5 * IQR\n",
    "#        - low: values < low whisker = Q1 - 1.5 * IQR\n",
    "#     where IQR = Q3 - Q1\n",
    "\n",
    "# let's artificially simulate this situation\n",
    "#     we will create a distortion in the values so that\n",
    "#     high values (close to 1) become even higher\n",
    "#     and low values (close to 0) become even lower\n",
    "\n",
    "\n",
    "def distortion(vals: Tensor) -> Tensor:\n",
    "    \"\"\"Artificial distortion to simulate a skewed distribution.\n",
    "\n",
    "    To visualize it:\n",
    "    ```\n",
    "    fig, ax = plt.subplots()\n",
    "    t = np.linspace(0, 1, 100)\n",
    "    ax.plot(t, np.clip(distortion(t), 0, 1), label=\"distortion\")\n",
    "    ax.plot(t, t, label=\"identity\", linestyle=\"--\")\n",
    "    fig\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return vals + 0.12 * (vals * (1 - vals) * 4)\n",
    "\n",
    "\n",
    "mock = torch.clip(distortion(aupimo_result.aupimos.clone()), 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "ax.boxplot(\n",
    "    mock[labels == 1].numpy(),\n",
    "    vert=False,\n",
    "    widths=0.4,\n",
    ")\n",
    "_ = ax.set_yticks([])\n",
    "ax.set_xlim(0 - (eps := 2e-2), 1 + eps)\n",
    "ax.xaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax.set_xlabel(\"AUPIMO [%]\")\n",
    "ax.set_title(\"AUPIMO Scores Boxplot\")\n",
    "num_images = (labels == 1).sum().item()\n",
    "ax.annotate(\n",
    "    text=f\"Number of images: {num_images}\",\n",
    "    xy=(0.03, 0.95),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(0, 0),\n",
    "    textcoords=\"offset points\",\n",
    "    annotation_clip=False,\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "fig  # noqa: B018, RUF100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `None` is the default policy, so the fliers are not returned\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, flier_policy=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one can choose to include only high or low fliers, or both\n",
    "# since there are only low fliers...\n",
    "\n",
    "# 'low' and 'both' will return the same result\n",
    "print(\"with option 'low'\")\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, flier_policy=\"low\")))\n",
    "\n",
    "print(\"with option 'both'\")\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, flier_policy=\"both\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and 'high' will return no fliers (same as `flier_policy=None` in this case)\n",
    "print(\"with option 'high'\")\n",
    "print(pd.DataFrame.from_records(boxplot_stats(mock, labels, flier_policy=\"high\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other applications and `only_label` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other applications\n",
    "#    since the function is agnostic to the meaning of the values\n",
    "#    we can also use it to find representative samples\n",
    "#    with another metric or signal\n",
    "#\n",
    "#    in the last plot cell we used the maximum anomaly score per image\n",
    "#    to select normal images, so let's reuse that criterion here\n",
    "\n",
    "# recompute it for didactic purposes\n",
    "max_anom_score_per_image = anomaly_maps.max(dim=2).values.max(dim=1).values  # noqa: PD011\n",
    "print(\"stats for the maximum anomaly score in the anomaly maps\")\n",
    "print(pd.DataFrame.from_records(boxplot_stats(max_anom_score_per_image, labels)))\n",
    "# notice that the indices are not the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use the `only_label` argument to select only the\n",
    "# samples from the normal class\n",
    "print(pd.DataFrame.from_records(boxplot_stats(max_anom_score_per_image, labels, only_label=0)))\n",
    "# notice the labels are all 0 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can consider data from both classes (`None` option)\n",
    "print(pd.DataFrame.from_records(boxplot_stats(max_anom_score_per_image, labels, only_label=None)))\n",
    "# notice that the labels are mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cite Us\n",
    "\n",
    "AUPIMO was developed during Google Summer of Code 2023 (GSoC 2023) with the `anomalib` team from OpenVINO Toolkit.\n",
    "\n",
    "Our work was accepted to the British Machine Vision Conference 2024 (BMVC 2024).\n",
    "\n",
    "```bibtex\n",
    "@misc{bertoldo2024aupimo,\n",
    "      title={{AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed and Low Tolerance}}, \n",
    "      author={Joao P. C. Bertoldo and Dick Ameln and Ashwin Vaidya and Samet Akçay},\n",
    "      year={2024},\n",
    "      eprint={2401.01984},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV},\n",
    "      url={https://arxiv.org/abs/2401.01984}, \n",
    "}\n",
    "```\n",
    "\n",
    "Paper on arXiv: [arxiv.org/abs/2401.01984](https://arxiv.org/abs/2401.01984) (accepted to BMVC 2024)\n",
    "\n",
    "Medium post: [medium.com/p/c653ac30e802](https://medium.com/p/c653ac30e802)\n",
    "\n",
    "Official repository: [github.com/jpcbertoldo/aupimo](https://github.com/jpcbertoldo/aupimo) (numpy-only API and numba-accelerated versions available)\n",
    "\n",
    "GSoC 2023 page: [summerofcode.withgoogle.com/archive/2023/projects/SPMopugd](https://summerofcode.withgoogle.com/archive/2023/projects/SPMopugd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
