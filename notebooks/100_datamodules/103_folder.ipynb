{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Folder Dataset (for Custom Datasets) via API\n",
    "\n",
    "Here we show how one can utilize custom datasets to train anomalib models. A custom dataset in this model can be of the following types:\n",
    "\n",
    "- A dataset with good and bad images.\n",
    "- A dataset with good and bad images as well as mask ground-truths for pixel-wise evaluation.\n",
    "- A dataset with good and bad images that is already split into training and testing sets.\n",
    "\n",
    "To experiment this setting we provide a toy dataset that could be downloaded from the following [https://github.com/openvinotoolkit/anomalib/blob/main/docs/source/data/hazelnut_toy.zip](link). For the rest of the tutorial, we assume that the dataset is downloaded and extracted to `../../datasets`, located in the `anomalib` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.data.folder import Folder, FolderDataset\n",
    "from anomalib.data.utils import InputNormalizationMethod, get_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderDataset??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `FolderDataset` we need to create the albumentations object that applies transforms to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transforms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = get_transforms(image_size=256, normalization=InputNormalizationMethod.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_classification_train = FolderDataset(\n",
    "    normal_dir=\"../../datasets/hazelnut_toy/good\",\n",
    "    abnormal_dir=\"../../datasets/hazelnut_toy/crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    task=\"classification\",\n",
    ")\n",
    "folder_dataset_classification_train.setup()\n",
    "folder_dataset_classification_train.samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_train[0]\n",
    "data.keys(), data[\"image\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Classification Test Set\n",
    "folder_dataset_classification_test = FolderDataset(\n",
    "    normal_dir=\"../../datasets/hazelnut_toy/good\",\n",
    "    abnormal_dir=\"../../datasets/hazelnut_toy/crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    task=\"classification\",\n",
    ")\n",
    "folder_dataset_classification_test.setup()\n",
    "folder_dataset_classification_test.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_test[0]\n",
    "data.keys(), data[\"image\"].shape, data[\"image_path\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the Folder dataset for the segmentation task, where the dataset object returns image and ground-truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Train Set\n",
    "folder_dataset_segmentation_train = FolderDataset(\n",
    "    normal_dir=\"../../datasets/hazelnut_toy/good\",\n",
    "    abnormal_dir=\"../../datasets/hazelnut_toy/crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    mask_dir=\"../../datasets/hazelnut_toy/mask/crack\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "folder_dataset_segmentation_train.setup()\n",
    "folder_dataset_segmentation_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Test Set\n",
    "folder_dataset_segmentation_test = FolderDataset(\n",
    "    normal_dir=\"../../datasets/hazelnut_toy/good\",\n",
    "    abnormal_dir=\"../../datasets/hazelnut_toy/crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    mask_dir=\"../../datasets/hazelnut_toy/mask/crack\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "folder_dataset_segmentation_test.setup()\n",
    "folder_dataset_segmentation_test.samples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_segmentation_test[3]\n",
    "data.keys(), data[\"image\"].shape, data[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(data[\"image\"].clone())\n",
    "msk = ToPILImage()(data[\"mask\"]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "So far, we have shown the Torch Dataset implementation of Folder dataset. This is quite useful to get a sample. However, when we train models end-to-end fashion, we do need much more than this such as downloading the dataset, creating train/val/test/inference dataloaders. To handle all these, we have the PyTorch Lightning DataModule implementation, which is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_datamodule = Folder(\n",
    "    root=\"../../datasets/hazelnut_toy/\",\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"crack\",\n",
    "    task=\"segmentation\",\n",
    "    mask_dir=\"../../datasets/hazelnut_toy/mask/crack\",\n",
    "    image_size=256,\n",
    "    normalization=InputNormalizationMethod.NONE,\n",
    ")\n",
    "folder_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "i, data = next(enumerate(folder_datamodule.train_dataloader()))\n",
    "data.keys(), data[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "i, data = next(enumerate(folder_datamodule.test_dataloader()))\n",
    "data.keys(), data[\"image\"].shape, data[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference. We could visualize samples from the dataloaders as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(data[\"image\"][0].clone())\n",
    "msk = ToPILImage()(data[\"mask\"][0]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Folder` data module offers much more flexibility cater all different sorts of needs. Please refer to the documentation for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7268ff2a6e4d53aca61388668d1ec7c6deba097b4c41661c6feb27adc61ca95b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
