{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `Folder` for Customs Datasets\n",
    "\n",
    "# Installing Anomalib\n",
    "\n",
    "The easiest way to install anomalib is to use pip. You can install it from the command line using the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anomalib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset Directory\n",
    "\n",
    "This cell is to ensure we change the directory to have access to the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# NOTE: Provide the path to the dataset root directory.\n",
    "#   If the datasets is not downloaded, it will be downloaded\n",
    "#   to this directory.\n",
    "dataset_root = Path.cwd().parent.parent / \"datasets\" / \"hazelnut_toy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Folder Dataset (for Custom Datasets) via API\n",
    "\n",
    "Here we show how one can utilize custom datasets to train anomalib models. A custom dataset in this model can be of the following types:\n",
    "\n",
    "- A dataset with good and bad images.\n",
    "- A dataset with good and bad images as well as mask ground-truths for pixel-wise evaluation.\n",
    "- A dataset with good and bad images that is already split into training and testing sets.\n",
    "\n",
    "To experiment this setting we provide a toy dataset that could be downloaded from the following [https://github.com/openvinotoolkit/anomalib/blob/main/docs/source/data/hazelnut_toy.zip](link). For the rest of the tutorial, we assume that the dataset is downloaded and extracted to `../datasets`, located in the `anomalib` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8: noqa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms.v2 import Resize\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "\n",
    "from anomalib.data import Folder, FolderDataset\n",
    "from anomalib import TaskType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "Similar to how we created the datamodules for existing benchmarking datasets in the previous tutorials, we can also create an Anomalib datamodule for our custom hazelnut dataset.\n",
    "\n",
    "In addition to the root folder of the dataset, we now also specify which folder contains the normal images, which folder contains the anomalous images, and which folder contains the ground truth masks for the anomalous images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_datamodule = Folder(\n",
    "    name=\"hazelnut_toy\",\n",
    "    root=dataset_root,\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"crack\",\n",
    "    task=TaskType.SEGMENTATION,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    ")\n",
    "folder_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "data = next(iter(folder_datamodule.train_data))\n",
    "print(data.image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "data = next(iter(folder_datamodule.test_data))\n",
    "print(data.image.shape, data.gt_mask.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference. We could visualize samples from the dataloaders as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = to_pil_image(data.image.clone())\n",
    "msk = to_pil_image(data.gt_mask.int() * 255).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Folder` data module offers much more flexibility cater all different sorts of needs. Please refer to the documentation for more details.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset\n",
    "\n",
    "As in earlier examples, we can also create a standalone PyTorch dataset instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderDataset??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some transforms that will be applied to the images using torchvision. Let's add a transform that resizes the \n",
    "input image to 256x256 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = Resize(image_size, antialias=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_classification_train = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_train.samples.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first sample in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_train[0]\n",
    "print(data.image.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Classification Test Set\n",
    "folder_dataset_classification_test = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "folder_dataset_classification_test.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_classification_test[0]\n",
    "print(data.image.shape, data.image_path, data.gt_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the Folder dataset for the segmentation task, where the dataset object returns image and ground-truth mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Train Set\n",
    "folder_dataset_segmentation_train = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"train\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    "    task=TaskType.SEGMENTATION,\n",
    ")\n",
    "folder_dataset_segmentation_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Segmentation Test Set\n",
    "folder_dataset_segmentation_test = FolderDataset(\n",
    "    name=\"hazelnut_toy\",\n",
    "    normal_dir=dataset_root / \"good\",\n",
    "    abnormal_dir=dataset_root / \"crack\",\n",
    "    split=\"test\",\n",
    "    transform=transform,\n",
    "    mask_dir=dataset_root / \"mask\" / \"crack\",\n",
    "    task=TaskType.SEGMENTATION,\n",
    ")\n",
    "folder_dataset_segmentation_test.samples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = folder_dataset_segmentation_test[3]\n",
    "print(data.image.shape, data.gt_mask.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = to_pil_image(data.image.clone())\n",
    "msk = to_pil_image(data.gt_mask.int() * 255).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae223df28f60859a2f400fae8b3a1034248e0a469f5599fd9a89c32908ed7a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
