{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MVTec AD Dataset via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.data.mvtec import MVTec, MVTecDataset\n",
    "from anomalib.data.utils import InputNormalizationMethod, get_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVTecDataset??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `MVTecDataset` we need to create the albumentations object that applies transforms to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transforms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "transform = get_transforms(image_size=256, normalization=InputNormalizationMethod.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec Classification Train Set\n",
    "mvtec_dataset_classification_train = MVTecDataset(\n",
    "    root=\"../../datasets/MVTec\",\n",
    "    category=\"bottle\",\n",
    "    transform=transform,\n",
    "    split=\"train\",\n",
    "    task=\"classification\",\n",
    ")\n",
    "mvtec_dataset_classification_train.setup()\n",
    "mvtec_dataset_classification_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mvtec_dataset_classification_train[0]\n",
    "sample.keys(), sample[\"image\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec Classification Test Set\n",
    "mvtec_dataset_classification_test = MVTecDataset(\n",
    "    root=\"../../datasets/MVTec\",\n",
    "    category=\"bottle\",\n",
    "    transform=transform,\n",
    "    split=\"test\",\n",
    "    task=\"classification\",\n",
    ")\n",
    "mvtec_dataset_classification_test.setup()\n",
    "sample = mvtec_dataset_classification_test[0]\n",
    "sample.keys(), sample[\"image\"].shape, sample[\"image_path\"], sample[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the MVTec dataset for the segmentation task, where the dataset object returns image and ground-truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec Segmentation Train Set\n",
    "mvtec_dataset_segmentation_train = MVTecDataset(\n",
    "    root=\"../../datasets/MVTec\",\n",
    "    category=\"bottle\",\n",
    "    transform=transform,\n",
    "    split=\"train\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "mvtec_dataset_segmentation_train.setup()\n",
    "mvtec_dataset_segmentation_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec Segmentation Test Set\n",
    "mvtec_dataset_segmentation_test = MVTecDataset(\n",
    "    root=\"../../datasets/MVTec\",\n",
    "    category=\"bottle\",\n",
    "    transform=transform,\n",
    "    split=\"test\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "mvtec_dataset_segmentation_test.setup()\n",
    "sample = mvtec_dataset_segmentation_test[20]\n",
    "sample.keys(), sample[\"image\"].shape, sample[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(sample[\"image\"].clone())\n",
    "msk = ToPILImage()(sample[\"mask\"]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "So far, we have shown the Torch Dateset implementation of MVTec AD dataset. This is quite useful to get a sample. However, when we train models end-to-end fashion, we do need much more than this such as downloading the dataset, creating train/val/test/inference dataloaders. To handle all these, we have the PyTorch Lightning DataModule implementation, which is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvtec_datamodule = MVTec(\n",
    "    root=\"../../datasets/MVTec\",\n",
    "    category=\"bottle\",\n",
    "    image_size=256,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    num_workers=8,\n",
    "    task=\"segmentation\",\n",
    "    normalization=InputNormalizationMethod.NONE,\n",
    ")\n",
    "mvtec_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "i, data = next(enumerate(mvtec_datamodule.train_dataloader()))\n",
    "data.keys(), data[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "i, data = next(enumerate(mvtec_datamodule.test_dataloader()))\n",
    "data.keys(), data[\"image\"].shape, data[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference. We could visualize samples from the dataloaders as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(data[\"image\"][0].clone())\n",
    "msk = ToPILImage()(data[\"mask\"][0]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.hstack((np.array(img), np.array(msk))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7268ff2a6e4d53aca61388668d1ec7c6deba097b4c41661c6feb27adc61ca95b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
